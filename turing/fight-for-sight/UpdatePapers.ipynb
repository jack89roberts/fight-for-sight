{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquiring a Dataset of Fight for Sight Publications\n",
    "\n",
    "Example of the page of a research publication on the EPMC website:\n",
    "* http://europepmc.org/abstract/MED/24439297\n",
    "\n",
    "Example response from the EPMC API for the same publication:\n",
    "* https://www.ebi.ac.uk/europepmc/webservices/rest/search?query=24439297&resultType=core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file directory operations\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "# for sleep command\n",
    "import time\n",
    "\n",
    "# to print some things nicely\n",
    "import textwrap\n",
    "\n",
    "# to deal with api requests\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# to save data\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the API Query - Search Criteria\n",
    "\n",
    "Search for \"fight for sight\" or its previous names in the metadata fields for Grant Agency and Acknowledgements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Criteria:\n",
      "------------------------------------------------------------\n",
      "GRANT_AGENCY:\"fight for sight\" OR\n",
      "ACK_FUND:\"fight for sight\" OR\n",
      "GRANT_AGENCY:\"iris fund for prevention of blindness\" OR\n",
      "ACK_FUND:\"iris fund for prevention of blindness\" OR\n",
      "GRANT_AGENCY:\"british eye research foundation\" OR\n",
      "ACK_FUND:\"british eye research foundation\" OR\n",
      "GRANT_AGENCY:\"prevention of blindness research fund\" OR\n",
      "ACK_FUND:\"prevention of blindness research fund\"\n"
     ]
    }
   ],
   "source": [
    "# API metadata fields to search in\n",
    "fields = ['GRANT_AGENCY','ACK_FUND']\n",
    "\n",
    "# terms to search for in those fields\n",
    "terms = ['fight for sight',\n",
    "         'iris fund for prevention of blindness',\n",
    "         'british eye research foundation',\n",
    "         'prevention of blindness research fund']\n",
    "\n",
    "# combine the fields and terms into string with correct\n",
    "# format for API\n",
    "query_str = ''\n",
    "\n",
    "for term in terms:\n",
    "    for field in fields:\n",
    "        query_str = query_str + field + ':\"' + term + '\" OR '\n",
    "\n",
    "query_str = query_str[:-4]\n",
    "\n",
    "print('Search Criteria:')\n",
    "print('-'*60)\n",
    "print(query_str.replace('OR ','OR\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the API Query - Response Options\n",
    "\n",
    "resultType=core: Return full meta-data for the paper, including abstracts etc.\n",
    "\n",
    "pageSize=1000: Return 1000 results per query (maximum allowed by API)\n",
    "\n",
    "format=json: Return the query in json format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Options:\n",
      "------------------------------------------------------------\n",
      "\n",
      "&resultType=core\n",
      "&pageSize=1000\n",
      "&format=json\n"
     ]
    }
   ],
   "source": [
    "options = {'resultType':'core','pageSize':'1000',\n",
    "           'format':'json'}\n",
    "\n",
    "options_str = ''\n",
    "\n",
    "for key,value in options.items():\n",
    "    options_str = options_str + '&'+key+'='+value\n",
    "\n",
    "print('Search Options:')\n",
    "print('-'*60)\n",
    "print(options_str.replace('&','\\n&'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the API Query - Full URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query URL:\n",
      "------------------------------------------------------------\n",
      "https://www.ebi.ac.uk/europepmc/webservices/rest/search?query=GRANT_AGENCY:\"fight for sight\" OR\n",
      "ACK_FUND:\"fight for sight\" OR GRANT_AGENCY:\"iris fund for prevention of blindness\" OR ACK_FUND:\"iris\n",
      "fund for prevention of blindness\" OR GRANT_AGENCY:\"british eye research foundation\" OR\n",
      "ACK_FUND:\"british eye research foundation\" OR GRANT_AGENCY:\"prevention of blindness research fund\"\n",
      "OR ACK_FUND:\"prevention of blindness research fund\"&resultType=core&pageSize=1000&format=json\n"
     ]
    }
   ],
   "source": [
    "base_url = 'https://www.ebi.ac.uk/europepmc/webservices/rest/search?query='\n",
    "base_url = base_url + query_str + options_str\n",
    "\n",
    "print('Query URL:')\n",
    "print('-'*60)\n",
    "print(textwrap.fill(base_url,width=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query the API\n",
    "\n",
    "As there are more than 1000 Fight for Sight related publications, the API needs to be queries multiple times to extract all the results. The \"cursorMark\" options is changed to return the second pages of results etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying EPMC...\n",
      "Querying page 1: 1602 hits total, 1000 in this page, 1000 collected so far.\n",
      "Querying page 2: 1602 hits total, 602 in this page, 1602 collected so far.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# define and create save directory\n",
    "save_name = 'ffs_papers'\n",
    "save_dir='data/EPMC/json/ffs_papers'\n",
    "\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# how many times to try a query before giving up\n",
    "n_attempts=10\n",
    "# how long to wait between queries (to limit rate)\n",
    "time_between_requests=1\n",
    "\n",
    "# initial parameters to enter loop\n",
    "nextCursorMark = '*'\n",
    "page_number = 0\n",
    "n_results = 0\n",
    "failed_count = 0\n",
    "n_response = 999999\n",
    "hit_count = 999999\n",
    "\n",
    "print('Querying EPMC...')\n",
    "\n",
    "# while new results left to return\n",
    "while (n_results<hit_count) and (n_response>0):\n",
    "    if failed_count==0:\n",
    "        print('Querying page '+str(page_number+1)+': ',end='')\n",
    "\n",
    "    try:\n",
    "        # add page number (cursorMark) to query str\n",
    "        query_full_url = base_url + '&cursorMark=' + str(nextCursorMark)  \n",
    "        \n",
    "        # query the api\n",
    "        response = requests.get(query_full_url)\n",
    "        response = response.json()\n",
    "        \n",
    "        # get the cursorMark (page) to query next time\n",
    "        nextCursorMark = response['nextCursorMark']\n",
    "\n",
    "        # check how many results were returned\n",
    "        n_response = len(response['resultList']['result'])\n",
    "        n_results = n_results + n_response\n",
    "        hit_count = response['hitCount']\n",
    "\n",
    "        print(hit_count,'hits total,',n_response,'in this page,',n_results,'collected so far.')\n",
    "\n",
    "    except:\n",
    "        # something went wrong with the query, try again\n",
    "        if failed_count>=n_attempts:\n",
    "            print(\"FAILED.\")\n",
    "        else:\n",
    "            # failed too many times, move on to the next page\n",
    "            failed_count = failed_count+1\n",
    "            time.sleep(time_between_requests)\n",
    "            continue\n",
    "\n",
    "    page_number = page_number+1\n",
    "\n",
    "    # if there are new results, save them to file\n",
    "    if (failed_count<n_attempts) and (n_response>0):\n",
    "        file_name = save_dir+'/'+save_name+'_page'+str(page_number).zfill(6)+'.json'\n",
    "\n",
    "        with open(file_name,'w') as f:\n",
    "            json.dump(response,f)\n",
    "\n",
    "    failed_count = 0\n",
    "\n",
    "    # wait a while before making the next request\n",
    "    time.sleep(time_between_requests)\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the JSON Files to a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_df(response, \n",
    "               columns=['abstractText','authorList','chemicalList',\n",
    "                        'citedByCount','doi','firstPublicationDate',\n",
    "                        'grantsList','id','journalInfo',\n",
    "                        'keywordList','meshHeadingList','pmcid',\n",
    "                        'pmid','pubYear','title']):\n",
    "                            \n",
    "    '''convert a single json response from the EPMC search API into a\n",
    "    pandas data frame. Any length 1 dictionaries or lists found in the\n",
    "    resulting columns are flattened.'''\n",
    "    \n",
    "    # extract the list of results from the json\n",
    "    df = pd.DataFrame(response['resultList']['result'])\n",
    "    # select subset of columns\n",
    "    df = df[[col for col in columns if df.columns.contains(col)]]\n",
    "    \n",
    "    for col in df.columns:\n",
    "        \n",
    "        # flatten length 1 dictionaries\n",
    "        is_dict = [type(x) is dict for x in df[col]]\n",
    "        \n",
    "        if sum(is_dict)>0:\n",
    "            # if all the entries in this column are a dict with only\n",
    "            # one key, the dicts can be replaced by their one value.\n",
    "            len1_dict = [len(x)==1 for x in df.loc[is_dict,col]]\n",
    "            \n",
    "            if all(len1_dict):\n",
    "                def extract_key_from_dict(the_dict):\n",
    "                    if (type(the_dict) is dict) and (len(the_dict)==1):\n",
    "                        key = list(the_dict.keys())\n",
    "                        key = key[0]\n",
    "                        return the_dict[key]\n",
    "                        \n",
    "                    else:\n",
    "                        return the_dict\n",
    "            \n",
    "                df[col] = df[col].apply(extract_key_from_dict)\n",
    "\n",
    "        # flatten length 1 lists\n",
    "        is_list = [type(x) is list for x in df[col]]\n",
    "        \n",
    "        if sum(is_list)>0:\n",
    "            # if all the entries in this column are a list with only\n",
    "            # one value, the lists can be replaced by their one value.\n",
    "            len1_list = [len(x)==1 for x in df.loc[is_list,col]]\n",
    "            \n",
    "            if all(len1_list):\n",
    "                def flatten_list(the_list):\n",
    "                    if (type(the_list) is list) and (len(the_list)==1):\n",
    "                        return the_list[0]\n",
    "                        \n",
    "                    else:\n",
    "                        return the_list\n",
    "            \n",
    "                df[col] = df[col].apply(flatten_list)\n",
    "       \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Data...\n",
      "1 out of 2 : data/EPMC/json/ffs_papers\\ffs_papers_page000001.json\n",
      "2 out of 2 : data/EPMC/json/ffs_papers\\ffs_papers_page000002.json\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstractText</th>\n",
       "      <th>authorList</th>\n",
       "      <th>chemicalList</th>\n",
       "      <th>citedByCount</th>\n",
       "      <th>doi</th>\n",
       "      <th>firstPublicationDate</th>\n",
       "      <th>grantsList</th>\n",
       "      <th>id</th>\n",
       "      <th>journalInfo</th>\n",
       "      <th>keywordList</th>\n",
       "      <th>meshHeadingList</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>pmid</th>\n",
       "      <th>pubYear</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The transepithelial potential difference (TEP)...</td>\n",
       "      <td>[{'fullName': 'Cao L', 'firstName': 'Lin', 'la...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>10.1111/jcmm.13829</td>\n",
       "      <td>2018-08-30</td>\n",
       "      <td>[{'grantId': '1361/1362', 'agency': 'Fight for...</td>\n",
       "      <td>30160348</td>\n",
       "      <td>{'issue': '11', 'volume': '22', 'journalIssueI...</td>\n",
       "      <td>[Atp1b1, Cell-cell Connection, Extracellular E...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PMC6201363</td>\n",
       "      <td>30160348</td>\n",
       "      <td>2018</td>\n",
       "      <td>Polarized retinal pigment epithelium generates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'fullName': 'Chen M', 'firstName': 'Mei', 'l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10.21037/atm.2018.10.31</td>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>[{'grantId': '1425/26', 'agency': 'Fight for S...</td>\n",
       "      <td>30613630</td>\n",
       "      <td>{'issue': 'Suppl 1', 'volume': '6', 'journalIs...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PMC6291610</td>\n",
       "      <td>30613630</td>\n",
       "      <td>2018</td>\n",
       "      <td>Cholesterol homeostasis, macrophage malfunctio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PURPOSE:Quantitative analysis of hyperautofluo...</td>\n",
       "      <td>[{'fullName': 'Tee JJL', 'firstName': 'James J...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10.1097/IAE.0000000000001871</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>[{'grantId': '1578/79', 'agency': 'Fight for S...</td>\n",
       "      <td>29016458</td>\n",
       "      <td>{'issue': '12', 'volume': '38', 'journalIssueI...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PMC5797695</td>\n",
       "      <td>29016458</td>\n",
       "      <td>2018</td>\n",
       "      <td>QUANTITATIVE ANALYSIS OF HYPERAUTOFLUORESCENT ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BACKGROUND:Uncontrolled microglial activation ...</td>\n",
       "      <td>[{'fullName': 'Wang L', 'firstName': 'Luxi', '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10.1186/s13024-019-0305-9</td>\n",
       "      <td>2019-01-11</td>\n",
       "      <td>[{'grantId': '1361/62', 'agency': 'Fight for S...</td>\n",
       "      <td>30634998</td>\n",
       "      <td>{'issue': '1', 'volume': '14', 'journalIssueId...</td>\n",
       "      <td>[Microglia, Retinal degeneration, neuroinflamm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PMC6329071</td>\n",
       "      <td>30634998</td>\n",
       "      <td>2019</td>\n",
       "      <td>Glucose transporter 1 critically controls micr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cell therapy using endothelial progenitors hol...</td>\n",
       "      <td>[{'fullName': 'Reid E', 'firstName': 'Emma', '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>10.1002/sctm.17-0187</td>\n",
       "      <td>2017-11-22</td>\n",
       "      <td>[{'grantId': '10JTA', 'agency': 'The Sir Jules...</td>\n",
       "      <td>29164803</td>\n",
       "      <td>{'issue': '1', 'volume': '7', 'journalIssueId'...</td>\n",
       "      <td>[Cell therapy, Stem Cells, Endothelial Progeni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PMC5746158</td>\n",
       "      <td>29164803</td>\n",
       "      <td>2018</td>\n",
       "      <td>Preclinical Evaluation and Optimization of a C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        abstractText  \\\n",
       "0  The transepithelial potential difference (TEP)...   \n",
       "1                                                NaN   \n",
       "2  PURPOSE:Quantitative analysis of hyperautofluo...   \n",
       "3  BACKGROUND:Uncontrolled microglial activation ...   \n",
       "4  Cell therapy using endothelial progenitors hol...   \n",
       "\n",
       "                                          authorList chemicalList  \\\n",
       "0  [{'fullName': 'Cao L', 'firstName': 'Lin', 'la...          NaN   \n",
       "1  [{'fullName': 'Chen M', 'firstName': 'Mei', 'l...          NaN   \n",
       "2  [{'fullName': 'Tee JJL', 'firstName': 'James J...          NaN   \n",
       "3  [{'fullName': 'Wang L', 'firstName': 'Luxi', '...          NaN   \n",
       "4  [{'fullName': 'Reid E', 'firstName': 'Emma', '...          NaN   \n",
       "\n",
       "   citedByCount                           doi firstPublicationDate  \\\n",
       "0             1            10.1111/jcmm.13829           2018-08-30   \n",
       "1             0       10.21037/atm.2018.10.31           2018-11-01   \n",
       "2             0  10.1097/IAE.0000000000001871           2018-12-01   \n",
       "3             0     10.1186/s13024-019-0305-9           2019-01-11   \n",
       "4             4          10.1002/sctm.17-0187           2017-11-22   \n",
       "\n",
       "                                          grantsList        id  \\\n",
       "0  [{'grantId': '1361/1362', 'agency': 'Fight for...  30160348   \n",
       "1  [{'grantId': '1425/26', 'agency': 'Fight for S...  30613630   \n",
       "2  [{'grantId': '1578/79', 'agency': 'Fight for S...  29016458   \n",
       "3  [{'grantId': '1361/62', 'agency': 'Fight for S...  30634998   \n",
       "4  [{'grantId': '10JTA', 'agency': 'The Sir Jules...  29164803   \n",
       "\n",
       "                                         journalInfo  \\\n",
       "0  {'issue': '11', 'volume': '22', 'journalIssueI...   \n",
       "1  {'issue': 'Suppl 1', 'volume': '6', 'journalIs...   \n",
       "2  {'issue': '12', 'volume': '38', 'journalIssueI...   \n",
       "3  {'issue': '1', 'volume': '14', 'journalIssueId...   \n",
       "4  {'issue': '1', 'volume': '7', 'journalIssueId'...   \n",
       "\n",
       "                                         keywordList meshHeadingList  \\\n",
       "0  [Atp1b1, Cell-cell Connection, Extracellular E...             NaN   \n",
       "1                                                NaN             NaN   \n",
       "2                                                NaN             NaN   \n",
       "3  [Microglia, Retinal degeneration, neuroinflamm...             NaN   \n",
       "4  [Cell therapy, Stem Cells, Endothelial Progeni...             NaN   \n",
       "\n",
       "        pmcid      pmid pubYear  \\\n",
       "0  PMC6201363  30160348    2018   \n",
       "1  PMC6291610  30613630    2018   \n",
       "2  PMC5797695  29016458    2018   \n",
       "3  PMC6329071  30634998    2019   \n",
       "4  PMC5746158  29164803    2018   \n",
       "\n",
       "                                               title  \n",
       "0  Polarized retinal pigment epithelium generates...  \n",
       "1  Cholesterol homeostasis, macrophage malfunctio...  \n",
       "2  QUANTITATIVE ANALYSIS OF HYPERAUTOFLUORESCENT ...  \n",
       "3  Glucose transporter 1 critically controls micr...  \n",
       "4  Preclinical Evaluation and Optimization of a C...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Processing Data...')\n",
    "\n",
    "# get the list of json files to combine\n",
    "json_paths = glob('data/EPMC/json/ffs_papers/*.json')\n",
    "\n",
    "# list to store dataframes for each json file\n",
    "df_list = []\n",
    "\n",
    "# loop over json files\n",
    "for idx,path in enumerate(sorted(json_paths)):\n",
    "    print(idx+1,'out of',len(json_paths),':',path)\n",
    "    \n",
    "    # load json\n",
    "    with open(path,'r') as f:\n",
    "        response = json.loads(f.read())\n",
    "\n",
    "    # convert json to data frame\n",
    "    new_df = json_to_df(response)\n",
    "\n",
    "    # add dataframe to the list\n",
    "    df_list.append(new_df)\n",
    "\n",
    "# combine all the dataframes into one\n",
    "df = pd.concat(df_list, ignore_index=True, sort=False)\n",
    "\n",
    "# check for and remove any duplicates\n",
    "# pandas duplicates can't deal with dicts so convert everything to str first\n",
    "df = df[~df.astype(str).duplicated()].reset_index(drop=True)\n",
    "\n",
    "# save the data frame in excel and pickle format\n",
    "df.to_excel('data/EPMC/ffs_papers.xlsx', index=False)\n",
    "df.to_pickle('data/EPMC/ffs_papers.pkl')\n",
    "\n",
    "print('Done.')\n",
    "\n",
    "display(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
